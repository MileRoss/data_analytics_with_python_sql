{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "22a8abca-d64b-4de5-8279-e20cf0cae733",
   "metadata": {},
   "source": [
    "# table of contents\n",
    "1. [predictions, part III](#predictions,-part-III)\n",
    "2. [preprocessing](#preprocessing)\n",
    "3. [oversampling](#oversampling)\n",
    "4. [undersampling](#undersampling)\n",
    "5. [SMOTE](#SMOTE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2001672e-9c5a-4ca6-a5e3-b28c5b2e48ec",
   "metadata": {},
   "source": [
    "# Predictions, part III\n",
    "- drop columns: no\n",
    "- scaling: yes\n",
    "- hyperparameter tuning: yes\n",
    "- one-hot encoding: yes, the dataset was found encoded\n",
    "- `resampling: yes`\n",
    "\n",
    "In this session, I'm addressing class imbalance in the target category.\\\n",
    "Target column \"is_canceled\" has 37% vs 63% for canceled vs not canceled bookings.\\\n",
    "I'm using 3 techniques:\n",
    "1. oversampling,\n",
    "2. undersampling,\n",
    "3. SMOTE.\n",
    "\n",
    "`The main takeaway from this session is that resampling doesn't improve performance of my models.`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b76d68e-c59e-4e37-9787-15732794aea7",
   "metadata": {},
   "source": [
    "# preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a140be2-49a8-4360-88be-b71aca245fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "%run common_imports.py\n",
    "\n",
    "# load and split data\n",
    "%run load_and_split_data.py\n",
    "X_train, X_test, y_train, y_test = load_and_split_data()\n",
    "\n",
    "# scale data\n",
    "%run minmaxscaler.py\n",
    "X_train_scaled, X_test_scaled = scale_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cab5e6f8-72a5-4fe8-9d7c-3ae26d4b98e9",
   "metadata": {},
   "source": [
    "# oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7467cbd-eeb0-4c7a-bfa3-969b9a71f2e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of X_train to avoid altering the original DataFrame\n",
    "X_train_cl = X_train.copy()\n",
    "\n",
    "# Add the 'is_canceled' column to X_train_cl\n",
    "X_train_cl[\"is_canceled\"] = y_train.values\n",
    "\n",
    "# Separate canceled and not_canceled instances\n",
    "canceled = X_train_cl[X_train_cl[\"is_canceled\"] == 1]\n",
    "not_canceled = X_train_cl[X_train_cl[\"is_canceled\"] == 0]\n",
    "\n",
    "# Visualize class distribution\n",
    "canceled_plt = X_train_cl[\"is_canceled\"].value_counts()\n",
    "canceled_plt.plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution Before Oversampling\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Oversample the minority class\n",
    "canceled_oversampled = resample(canceled,\n",
    "                                replace=True,\n",
    "                                n_samples=len(not_canceled),\n",
    "                                random_state=0)\n",
    "\n",
    "# Concatenate oversampled minority class with majority class\n",
    "train_over = pd.concat([canceled_oversampled, not_canceled])\n",
    "\n",
    "# Update X_train and y_train with the oversampled data\n",
    "X_train = train_over.drop(columns=[\"is_canceled\"])\n",
    "y_train = train_over[\"is_canceled\"]\n",
    "\n",
    "# Standardize the oversampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify the shapes of X_train and y_train\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "\n",
    "# Visualize class distribution after oversampling\n",
    "canceled_plt = train_over[\"is_canceled\"].value_counts()\n",
    "canceled_plt.plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution After Oversampling\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ed70b4-438c-4269-b240-33908b54ae05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to process the hyperparameter tuning results\n",
    "from train_with_best_hyperparameters import process_hyperparameter_tuning_results\n",
    "\n",
    "process_hyperparameter_tuning_results(\n",
    "    input_file=\"../data/hyperparameter_tuning_results.csv\", \n",
    "    output_file=\"../data/accuracies_with_parameters_oversampled.csv\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    X_train_scaled=X_train_scaled,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6f8a629-1b07-45ba-8065-3933d6dcb340",
   "metadata": {},
   "source": [
    "# undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed9caae-6499-4888-8a3e-e2660e09ca46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a copy of X_train to avoid altering the original DataFrame\n",
    "X_train_copy = X_train.copy()\n",
    "\n",
    "# Add the 'is_canceled' column to X_train_copy\n",
    "X_train_copy[\"is_canceled\"] = y_train.values\n",
    "\n",
    "# Separate canceled and not_canceled instances\n",
    "canceled = X_train_copy[X_train_copy[\"is_canceled\"] == 1]\n",
    "not_canceled = X_train_copy[X_train_copy[\"is_canceled\"] == 0]\n",
    "\n",
    "# Visualize class distribution\n",
    "canceled_plt = X_train_copy[\"is_canceled\"].value_counts()\n",
    "canceled_plt.plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution Before Undersampling\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Undersample the majority class\n",
    "not_canceled_undersampled = resample(not_canceled,\n",
    "                                     replace=False,\n",
    "                                     n_samples=len(canceled),\n",
    "                                     random_state=0)\n",
    "\n",
    "# Concatenate undersampled majority class with minority class\n",
    "train_under = pd.concat([not_canceled_undersampled, canceled])\n",
    "\n",
    "# Update X_train and y_train with the undersampled data\n",
    "X_train = train_under.drop(columns=[\"is_canceled\"])\n",
    "y_train = train_under[\"is_canceled\"]\n",
    "\n",
    "# Standardize the undersampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Verify the shapes of X_train and y_train\n",
    "print(f\"Shape of X_train: {X_train.shape}\")\n",
    "print(f\"Shape of y_train: {y_train.shape}\")\n",
    "\n",
    "# Visualize class distribution after undersampling\n",
    "canceled_plt = train_under[\"is_canceled\"].value_counts()\n",
    "canceled_plt.plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution After Undersampling\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf97d7cd-2884-45db-bc49-b59eb4f97e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to process the hyperparameter tuning results\n",
    "from train_with_best_hyperparameters import process_hyperparameter_tuning_results\n",
    "\n",
    "process_hyperparameter_tuning_results(\n",
    "    input_file=\"../data/hyperparameter_tuning_results.csv\", \n",
    "    output_file=\"../data/accuracies_with_parameters_undersampled.csv\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    X_train_scaled=X_train_scaled,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8f0f71d-098b-4751-af6c-ed7a8ae33b36",
   "metadata": {},
   "source": [
    "# SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fbd28d7-11f0-4c2e-93aa-aa300e0c6727",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize class distribution before SMOTE\n",
    "canceled_plt_before = y_train.value_counts()\n",
    "canceled_plt_before.plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution Before SMOTE\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()\n",
    "\n",
    "# Apply SMOTE and reassign to the original variable names\n",
    "sm = SMOTE(random_state=1, sampling_strategy=1.0)\n",
    "X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "# Standardize the resampled data\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)  # Assuming X_test needs to be standardized similarly\n",
    "\n",
    "# Visualize class distribution after SMOTE\n",
    "canceled_plt_after = y_train.value_counts()\n",
    "canceled_plt_after.plot(kind=\"bar\")\n",
    "plt.title(\"Class Distribution After SMOTE\")\n",
    "plt.xlabel(\"Class\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc3d885-d1e0-4ddf-af72-c80edf488fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Call the function to process the hyperparameter tuning results\n",
    "from train_with_best_hyperparameters import process_hyperparameter_tuning_results\n",
    "\n",
    "process_hyperparameter_tuning_results(\n",
    "    input_file=\"../data/hyperparameter_tuning_results.csv\", \n",
    "    output_file=\"../data/accuracies_with_parameters_smote.csv\",\n",
    "    X_train=X_train,\n",
    "    X_test=X_test,\n",
    "    y_train=y_train,\n",
    "    X_train_scaled=X_train_scaled,\n",
    "    X_test_scaled=X_test_scaled,\n",
    "    y_test=y_test\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "121935f6-596a-4224-a031-88ac738654c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "accuracies_with_parameters = pd.read_csv(\"../data/accuracies_with_parameters.csv\")\n",
    "accuracies_with_parameters_oversampled = pd.read_csv(\"../data/accuracies_with_parameters_oversampled.csv\")\n",
    "accuracies_with_parameters_undersampled = pd.read_csv(\"../data/accuracies_with_parameters_undersampled.csv\")\n",
    "accuracies_with_parameters_smote = pd.read_csv(\"../data/accuracies_with_parameters_smote.csv\")\n",
    "\n",
    "# Identify the best accuracy for each model in each dataframe\n",
    "idx = accuracies_with_parameters.groupby(\"model\")[\"accuracy_in_%\"].idxmax()\n",
    "best_params = accuracies_with_parameters.loc[idx, [\"model\", \"best_parameters\", \"accuracy_in_%\", \"source\"]].reset_index(drop=True)\n",
    "best_params[\"dataset\"] = \"original\"\n",
    "\n",
    "idx_oversampled = accuracies_with_parameters_oversampled.groupby(\"model\")[\"accuracy_in_%\"].idxmax()\n",
    "best_params_oversampled = accuracies_with_parameters_oversampled.loc[idx_oversampled, [\"model\", \"best_parameters\", \"accuracy_in_%\", \"source\"]].reset_index(drop=True)\n",
    "best_params_oversampled[\"dataset\"] = \"oversampled\"\n",
    "\n",
    "idx_undersampled = accuracies_with_parameters_undersampled.groupby(\"model\")[\"accuracy_in_%\"].idxmax()\n",
    "best_params_undersampled = accuracies_with_parameters_undersampled.loc[idx_undersampled, [\"model\", \"best_parameters\", \"accuracy_in_%\", \"source\"]].reset_index(drop=True)\n",
    "best_params_undersampled[\"dataset\"] = \"undersampled\"\n",
    "\n",
    "idx_smote = accuracies_with_parameters_smote.groupby(\"model\")[\"accuracy_in_%\"].idxmax()\n",
    "best_params_smote = accuracies_with_parameters_smote.loc[idx_smote, [\"model\", \"best_parameters\", \"accuracy_in_%\", \"source\"]].reset_index(drop=True)\n",
    "best_params_smote[\"dataset\"] = \"smote\"\n",
    "\n",
    "# Combine the results into a single dataframe\n",
    "combined_results = pd.concat([best_params, best_params_oversampled, best_params_undersampled, best_params_smote], ignore_index=True)\n",
    "\n",
    "# Sort the combined results\n",
    "accuracies_sorted = combined_results.sort_values(by=[\"model\", \"accuracy_in_%\", \"dataset\"], ascending=[True, False, True])\n",
    "\n",
    "# Save the sorted dataframe\n",
    "accuracies_sorted.to_csv(\"../data/accuracies_resampled.csv\", index=False)\n",
    "\n",
    "# Display the dataframe\n",
    "accuracies_sorted"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
